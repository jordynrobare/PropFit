<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.6">
<title>propfit.propfit API documentation</title>
<meta name="description" content="">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source > summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible;min-width:max-content}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin:1em 0}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
/* Collapse source docstrings */
setTimeout(() => {
[...document.querySelectorAll('.hljs.language-python > .hljs-string')]
.filter(el => el.innerHTML.length > 200 && ['"""', "'''"].includes(el.innerHTML.substring(0, 3)))
.forEach(el => {
let d = document.createElement('details');
d.classList.add('hljs-string');
d.innerHTML = '<summary>"""</summary>' + el.innerHTML.substring(3);
el.replaceWith(d);
});
}, 100);
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>propfit.propfit</code></h1>
</header>
<section id="section-intro">
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="propfit.propfit.PropFit"><code class="flex name class">
<span>class <span class="ident">PropFit</span></span>
<span>(</span><span>filename=None,<br>props=['Gh', 'Hh', 'Cph', 'V', 'Hig', 'Sig', 'Cpig'],<br>group_file=None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class PropFit(Estimate):
    
    &#34;&#34;&#34;
    Regress thermodynamic properties of molecular groups for use in estimation of compounds with no experimental data.
    
    Parameters
    ----------
    filename : str
        Name of csv with compound names and thermodynamic properties you want to regress.

    props : list of strings
        Thermodynamic properties you want to regress group data for. Must match the property columns in the input file. 
    &#34;&#34;&#34;
    
    def __init__(self, filename=None, props=[&#39;Gh&#39;,&#39;Hh&#39;,&#39;Cph&#39;,&#39;V&#39;,&#39;Hig&#39;,&#39;Sig&#39;,&#39;Cpig&#39;], group_file=None): 

        if isinstance(filename, str):
            self.input_df = pd.read_csv(filename)

        else:
            with import_package_file(__name__, &#39;default databases/default database.csv&#39;, as_file=True) as path:
                self.input_df = pd.read_csv(path)
                
        if isinstance(group_file, str):
            self.group_df = pd.read_csv(group_file)
        else:
            self.group_df = None
                    
        self.props = props
        self.smiles = None
        self.err_handler = Error_Handler(clean=False)
        
    def dataprep(self, average=True, order=2, output_name = None):
    
        &#34;&#34;&#34;
        Prepare a dataframe that consists of molecule names, properties, and group match data.
        
        Parameters
        ----------
        average : bool, default True
            Average repeat measurements for compound properties?
    
        order : numeric or str, default 2
            Order of approximation for splitting molecules into groups. Accepts &#34;2&#34;, 2, &#34;1&#34;, 1, or &#39;custom&#39;. 
            If &#39;custom&#39;, you must provide a group matching csv named &#39;custom groups.csv&#39;.  
    
        output_name : str, default &#39;properties and groups.csv&#39;
            Name of the CSV file that will be generated. 
        &#34;&#34;&#34;
        input_df = self.input_df
        smile_df = input_df.copy()
        if output_name == None:
            output_name = &#39;properties and groups.csv&#39;
        else:
            output_name = output_name

        for c in list(input_df.columns)[1:]:
            if c not in self.props:
                input_df.drop(c, axis=1, inplace=True)
                
        if average==True:
            new_df = pd.DataFrame(columns = input_df.columns)
            for i in input_df.index:
                c = input_df.loc[i, &#39;compound&#39;]
                if c not in list(new_df.compound):
                    new_df.loc[i, &#39;compound&#39;] = c
                    for p in self.props:
                        temp_df = input_df.loc[input_df[&#39;compound&#39;] == c].loc[~input_df[p].isnull()]
                        if len(temp_df)&gt;0:
                            new_df.loc[i, p] = np.nanmean(temp_df[p])
            input_df = new_df

        if isinstance(self.group_df, pd.DataFrame):
            group_df = self.group_df
        elif order == 1 or order == &#39;1&#39;:
            with import_package_file(__name__, &#39;default databases/1st order groups.csv&#39;, as_file=True) as path:
                group_df = pd.read_csv(path)
        elif order == 2 or order == &#39;2&#39;:
            with import_package_file(__name__, &#39;default databases/2nd order groups.csv&#39;, as_file=True) as path:
                group_df = pd.read_csv(path)
        
        group_df.replace(np.nan, &#39;&#39;, inplace=True)
        self.group_df = group_df

        keys = list(group_df[&#39;keys&#39;])
        values = list(group_df[&#39;values&#39;])
        pattern_dict = dict(zip(keys, values))
        for key in pattern_dict:
            if str(pattern_dict[key]) == &#39;nan&#39;:
                pattern_dict[key] = &#39;&#39;

        self.pattern_dict = pattern_dict
        
        keys += [&#39;formula&#39;]
        df = pd.DataFrame(columns = [&#39;compound&#39;]+keys)
        vetted_mol = []
        ind = 0

        molecules = list(input_df[&#34;compound&#34;])
        for molecule in molecules:
            if molecule not in vetted_mol:
                self.name = molecule

                temp_smile_df = smile_df.loc[smile_df[&#39;compound&#39;]==molecule].loc[~smile_df[&#39;SMILES&#39;].isnull()].copy()
                if len(temp_smile_df)&gt;0:
                    self.smiles = temp_smile_df[&#39;SMILES&#39;].values[0]
                else:
                    self.pcp_compound = pcp.get_compounds(self.name, &#34;name&#34;)
                    self.smiles = self.pcp_compound[0].connectivity_smiles
                
                self.get_mol_smiles_formula_formula_dict()
                temp_dict = self.match_groups()
                values = list(temp_dict.values())
                temp_df = pd.DataFrame(columns = [&#39;compound&#39;]+keys)
                temp_df.loc[0, &#39;compound&#39;] = molecule
                temp_df.loc[0, keys] = values
                df = pd.concat([df, temp_df])
                vetted_mol.append(molecule)

        failures = len(vetted_mol) - len(molecules)
        if failures &gt; 0:
            print(&#39;There were &#39;+str(failures)+&#39; molecules that did not work&#39;)
            print([m for m in molecules if m not in vetted_mol])

        ### now add props
        key_df = pd.DataFrame(columns = keys)
        for k in keys:
            key_df[k] = [np.nan]*len(input_df)
        prop_df = pd.concat([input_df, key_df], axis=1)
        prop_df[&#39;formula&#39;] = prop_df[&#39;formula&#39;].astype(str)

        prop_df = prop_df.loc[~prop_df[&#39;compound&#39;].isnull()]        
        for i in prop_df.index:
            compound = prop_df.loc[i, &#39;compound&#39;]
            values = list(df.loc[df[&#39;compound&#39;] == compound][keys].values[0])
            prop_df.loc[i, keys] = values
    
        prop_df.to_csv(output_name, index=False)
        print(output_name + &#39; created&#39;)
    
    def group_property_estimator(self, filename, props=None, ignore = None):
        
        &#34;&#34;&#34;
        Regress the properties of group matches based on thermodynamic properties of molecules and molecular group matches.
        
        Parameters
        ----------
        filename : str
            Name of the file containing compounds, properties, and group matching data. 
    
        props : list of strings
            Thermodynamic properties you want to regress group data for. Must match the property columns in the input file. 
    
        ignore : list of strings
            Name of columns in the input file which are not thermodynamic properties and therefore should not be regressed. 
        &#34;&#34;&#34;
        if not isinstance(props, list):
            props=self.props

        df1 = pd.read_csv(filename)
        
        if isinstance(ignore, list):
            df1.drop(ignore, axis=1, inplace=True)

        bad_props = []
        for p in props:
            if p not in list(df1.columns):
                bad_props.append(p)
                
        props = [p for p in props if p not in bad_props]
            
        for dependent_param in props:
            df_data = df1.copy()
            
            # remove columns containing 0 groups
            df_data = df_data.loc[:, (df_data != 0).any(axis=0)]
        
            # get data subset that needs a prediction
            df_topred = df_data[np.isfinite(df_data[dependent_param]) == False]
            
            # get data subset that does not need a prediction
            df_not_topred = df_data[np.isfinite(df_data[dependent_param]) == True]
            
            # delete rows representing compounds that need a prediction when they contain a group that is not
            # represented in the training set.
            delrows = []
            for col in df_not_topred.columns.values:
                try:
                    if sum(df_not_topred[col]) == 0:
                        for row in df_topred.index.values:
                            if df_topred.loc[row, col] != 0:
                                delrows.append(row)
                except:
                    pass
            bad_df = df_topred.index.isin(delrows)
            df_topred = df_topred[~bad_df]
            
            # remove rows without y values
            df_data = df_data[np.isfinite(df_data[dependent_param])]
        
            X = df_data[[x for x in list(df_data.columns.values) if not x in [&#34;compound&#34;, &#34;formula&#34;, dependent_param]+props]].copy()
            y = df_data[dependent_param].copy()
            X_topred = df_topred[[x for x in list(df_topred.columns.values) if not x in [&#34;compound&#34;, &#34;formula&#34;, dependent_param]+props]].copy()

            if &#39;ig&#39; not in dependent_param:
                
                ## add material point
                X.loc[:, &#34;material point&#34;] = [1]* len(X)
                X_topred.loc[:, &#34;material point&#34;] = [1]* len(X_topred)
                
            multi_reg = sm.OLS(y[0:], X[0:]).fit() # perform the multiple regression
            prediction = multi_reg.predict(X) # make the predictions from the multi_reg
            preds = multi_reg.predict(X_topred)
            
            material_point = 0 
            material_point_err = 0
                
            group_property_dict = dict(zip(X.columns.values, [round(val, 4) for val in multi_reg.params.values]))
            group_property_se_dict = dict(zip(X.columns.values, [round(val, 4) for val in multi_reg.bse.values]))
            pred_errs = [sum([n_group*group_property_se_dict[group]**2 for n_group, group in zip(X.loc[idx], X.columns.values)])**0.5 for idx in X.index]
            topred_errs = [sum([n_group*group_property_se_dict[group]**2 for n_group, group in zip(X_topred.loc[idx], X_topred.columns.values)])**0.5 for idx in X_topred.index]
            
            comp_pred_df = pd.DataFrame({&#34;compound&#34;:list(df_data[&#34;compound&#34;]),
                                         &#34;actual&#34;:df_data[dependent_param],
                                         &#34;prediction&#34;:[round(pred+material_point, 2) for pred in prediction.values],
                                         &#34;pred errs&#34;:[round(err, 2) for err in pred_errs]})
            
            df_preds = pd.DataFrame({&#34;compound&#34;:list(df_topred[&#34;compound&#34;]),
                                        &#34;actual&#34;:df_topred[dependent_param],
                                         &#34;prediction&#34;:[round(pred+material_point, 2) for pred in preds.values],
                                         &#34;pred errs&#34;:[round(err, 2) for err in topred_errs]})
            
            df_final = pd.concat([comp_pred_df,df_preds]) #is this happening on the right axis?
            
            with pd.option_context(&#39;display.max_rows&#39;, None, &#39;display.max_columns&#39;, None):
                df_group_property = pd.DataFrame(group_property_dict.items(), columns=[&#39;group&#39;, &#39;value&#39;])
                df_group_se = pd.DataFrame(group_property_se_dict.items(), columns=[&#39;group&#39;, &#39;std err&#39;])

            save_as = filename.split(&#39;.csv&#39;)[0]+&#39; regressed&#39;

            df_final.to_csv(save_as+&#34;_&#34;+dependent_param+&#34;.csv&#34;, index=False)
            df_group_property.to_csv(save_as+&#34;_&#34;+dependent_param+&#34;_group_property.csv&#34;, index=False) #reports 0s when not able to estimate
            df_group_se.to_csv(save_as+&#34;_&#34;+dependent_param+&#34;_group_se.csv&#34;, index=False)

    def generate(self, filename = &#39;properties and groups regressed&#39;, order=2, hyd_props = [&#39;Gh&#39;,&#39;Hh&#39;,&#39;Cph&#39;,&#39;V&#39;], gas_props = [&#39;Hig&#39;,&#39;Sig&#39;,&#39;Cpig&#39;]):
        
        &#34;&#34;&#34;
        Generate the group thermodynamic property databases needed to put into AqOrg&#39;s Estimate() function.
        
        Parameters
        ----------
        filename : str, default &#39;properties and groups regressed&#39;
            Common start to filenames that were generated in the group_property_estimaor() function. 
    
        order : numeric or str, default 2
            Order of approximation for splitting molecules into groups. Accepts &#34;2&#34;, 2, &#34;1&#34;, 1, or &#39;custom&#39;. 
            If &#39;custom&#39;, you must provide a group matching csv named &#39;custom groups.csv&#39;.
            This has to match the order which was used to make the properties and groups dataframe. 
            
        hyd_props : list of strings, default [&#39;Gh&#39;,&#39;Hh&#39;,&#39;Cph&#39;,&#39;V&#39;]
            Thermodynamic properties of hydration you want to regress group data for. Must match the property columns in the input file. 

        gas_props : list of strings, default [&#39;Hig&#39;,&#39;Sig&#39;,&#39;Cpig&#39;]
            Thermodynamic properties of formation of ideal gases you want to regress group data for. Must match the property columns in the input file.

        &#34;&#34;&#34;
        save_as = filename
        hyd_cols = []
        for h in hyd_props:
            hyd_cols += [h, h+&#39;_err&#39;, h+&#39;_n&#39;]

        gas_cols = []
        for g in gas_props:
            gas_cols += [g, g+&#39;_err&#39;, g+&#39;_n&#39;]

        group_df = self.group_df
    
        keys = list(group_df[&#39;keys&#39;])
        values = list(group_df[&#39;values&#39;])
        pattern_dict = dict(zip(keys, values))
        for key in pattern_dict:
            if str(pattern_dict[key]) == &#39;nan&#39;:
                pattern_dict[key] = &#39;&#39;

        self.pattern_dict = pattern_dict
        
        hyd = pd.DataFrame(columns = [&#39;group&#39;]+hyd_cols+[&#39;smarts&#39;,&#39;elem&#39;])
        temp_df = pd.read_csv(save_as+&#39;_&#39;+hyd_props[0]+&#39;_group_property.csv&#39;)
        for i in temp_df.index:
            group = temp_df.loc[i, &#39;group&#39;]
            hyd.loc[i, &#39;group&#39;] = group
            hyd.loc[i, &#39;smarts&#39;] = group
            if group != &#39;material point&#39;:
                hyd.loc[i, &#39;elem&#39;] = self.pattern_dict[group]

        group_df = pd.read_csv(save_as.split(&#39; regressed&#39;)[0]+&#39;.csv&#39;)
        ind = max([list(group_df.columns).index(p) for p in self.props])+1  
        end = list(group_df.columns).index(&#39;formula&#39;)
        groups = list(group_df.columns)[ind:end]

        remove = []
        for p in hyd_props:
            prop_df = pd.read_csv(save_as+&#39;_&#39;+p+&#39;_group_property.csv&#39;)
            err_df = pd.read_csv(save_as+&#39;_&#39;+p+&#39;_group_se.csv&#39;)
            for i in prop_df.index:
                group = prop_df.loc[i, &#39;group&#39;]
                value = prop_df.loc[i, &#39;value&#39;]
                if err_df.loc[i, &#39;group&#39;] != group:
                    print(&#39;err&#39;)
                if value == 0 and i not in remove:
                    remove.append(i)
                if value != 0:
                    err = err_df.loc[i, &#39;std err&#39;]
                    cnt = 0
                    if group != &#39;material point&#39;:
                        cnt = group_df.loc[group_df[group]&gt;0][p].count()                        
                    hyd.loc[i, p] = value
                    hyd.loc[i, p+&#39;_err&#39;] = err
                    hyd.loc[i, p+&#39;_n&#39;] = cnt
        hyd.drop(remove, inplace=True)

        gas = pd.DataFrame(columns = [&#39;group&#39;]+gas_cols+[&#39;smarts&#39;,&#39;elem&#39;])
        temp_df = pd.read_csv(save_as+&#39;_&#39;+gas_props[0]+&#39;_group_property.csv&#39;)
        for i in temp_df.index:
            group = temp_df.loc[i, &#39;group&#39;]
            gas.loc[i, &#39;group&#39;] = group
            gas.loc[i, &#39;smarts&#39;] = group
            if group != &#39;material point&#39;:
                gas.loc[i, &#39;elem&#39;] = self.pattern_dict[group]
    
        remove = []
        for p in gas_props:
            prop_df = pd.read_csv(save_as+&#39;_&#39;+p+&#39;_group_property.csv&#39;)
            err_df = pd.read_csv(save_as+&#39;_&#39;+p+&#39;_group_se.csv&#39;)
            for i in prop_df.index:
                group = prop_df.loc[i, &#39;group&#39;]
                value = prop_df.loc[i, &#39;value&#39;]
                if err_df.loc[i, &#39;group&#39;] != group:
                    print(&#39;err&#39;)
                if value == 0 and i not in remove:
                    remove.append(i)
                if value != 0:
                    err = err_df.loc[i, &#39;std err&#39;]
                    cnt = 0
                    if group != &#39;material point&#39;:
                        cnt = group_df.loc[group_df[group]&gt;0][p].count()                        
                    gas.loc[i, p] = value
                    gas.loc[i, p+&#39;_err&#39;] = err
                    gas.loc[i, p+&#39;_n&#39;] = cnt
        gas.drop(remove, inplace=True)
        gas.insert(1, &#39;Gig&#39;, np.nan)

        for i in gas.index:
            elements = gas.loc[i, &#39;elem&#39;]
            if str(elements) not in [&#39;nan&#39;, &#39;&#39;]:
                Selem = entropy(elements)*4.184
                Sig = gas.loc[i, &#39;Sig&#39;]
                dS = Sig - Selem
                gas.loc[i, &#39;Gig&#39;] = round((gas.loc[i, &#39;Hig&#39;]*1000 - 298.15*dS)/1000, 3)

        gas_ind = max(gas.index)+1
        gas.loc[gas_ind, :] = 0
        gas.loc[gas_ind, &#39;group&#39;]=&#39;Yo&#39;
        gas.loc[gas_ind, &#39;smarts&#39;]=&#39;Yo&#39;

        hyd_ind = hyd.loc[hyd[&#39;group&#39;]==&#39;material point&#39;].index[0]
        hyd.loc[hyd_ind, &#39;group&#39;]=&#39;Yo&#39;
        hyd.loc[hyd_ind, &#39;smarts&#39;]=&#39;Yo&#39;

        gas.to_csv(&#39;gas props.csv&#39;, index=False)
        hyd.to_csv(&#39;hyd props.csv&#39;, index=False)
        
    def tts(self, repeats = 100, test_size = 0.2, filename = None, output_name = &#39;stats df.csv&#39;, show=True):

        &#34;&#34;&#34;
        Perform a train-test split on the thermodynamic data you will regress and estimate properties from. 
        
        Parameters
        ----------
        repeats: int, default 100
            Number of semi-random iterations of train-test splitting to do. The iterations will be used to calculate statistics associated with the semi-random sampling process.     

        test_size: float, default 0.2
            Fraction of the database for each thermodynamic property that should be used as the test set.  
        
        filename : str, default properties and groups.csv
            Common start to filenames that were generated in the group_property_estimaor() function. 

        output_name : str, default &#39;stats df.csv&#39;
            Name of the CSV file that will be generated, composed of the average and standard deviation of the RMSEs of estimations associated with each iterations. 

        show : bool, default True
            Show barplot for training and test data for each property? 
        &#34;&#34;&#34;
        if filename == None:
            filename = &#39;properties and groups.csv&#39;
        
        df = pd.read_csv(filename)
        stats_df = pd.DataFrame()
        for prop_ind, p in enumerate(self.props):
            temp_props = self.props.copy()
            temp_props.remove(p)
            prop_df = df.loc[~df[p].isnull()].drop(temp_props, axis=1)
            prop_df.reset_index(inplace=True, drop=True)
            for c in prop_df.columns[2:-1]:
                if sum(prop_df[c]) == 0:
                    prop_df.drop(c, axis=1, inplace=True)
    
            groups = list(prop_df.columns)[2:-1]
            data_len = len(prop_df)
            prop = prop_df.columns[1]
            compounds = []
            for c in list(prop_df[&#39;compound&#39;]):
                if c not in compounds:
                    compounds.append(c)
    
            ### sorting by least represented groups to make sampling easier below
            lengths = []
            for g in groups:
                length = len(prop_df.loc[prop_df[g]&gt;0]) #how many times is the group represented
                lengths.append(length)
            length_df = pd.DataFrame()
            length_df[&#39;groups&#39;] = groups
            length_df[&#39;lengths&#39;] = lengths
            length_df.sort_values(by = &#39;lengths&#39;, inplace=True) #least common groups first
            groups = list(length_df[&#39;groups&#39;])
        
            ### choosing one rep per group
            reps = []
            for g in groups:
                mols_w_data = []
                temp_df = prop_df.loc[prop_df[g]&gt;0].loc[~prop_df[&#39;compound&#39;].isin(reps)]
                if len(temp_df)&gt;0:
                    for c in temp_df.compound:
                        if c not in mols_w_data:
                            mols_w_data.append(c)
                    reps.append(random.sample(mols_w_data, 1)[0])
            non_reps = [c for c in compounds if c not in reps]
            train = reps.copy()
            test = non_reps.copy()
        
            test_df = prop_df.loc[prop_df[&#39;compound&#39;].isin(test)]
            train_df = prop_df.loc[prop_df[&#39;compound&#39;].isin(train)]
        
            test_df.to_csv(p+&#39;_test.csv&#39;, index=False) 
            train_df.to_csv(p+&#39;_train.csv&#39;, index=False) 
    
            train_RMSEs = []
            test_RMSEs = []
            
            for r in range(0, repeats):
        
                test_df = pd.read_csv(p+&#39;_test.csv&#39;)
                train_df = pd.read_csv(p+&#39;_train.csv&#39;) ## bare min training set so all groups are represented
                total_df = pd.concat([train_df, test_df], ignore_index=True)
                
                compounds = []
                test = []
                train = []
                for j in total_df.index:
                    compound = total_df.loc[j, &#39;compound&#39;]
                    if compound not in compounds:
                        compounds.append(compound)
                        if compound in list(test_df[&#39;compound&#39;]) and compound not in test:
                            test.append(compound)
                        if compound in list(train_df[&#39;compound&#39;]) and compound not in train:
                            train.append(compound)
                            
                ## randomly harvesting more data for training set
                for i in range(0, len(test)):
                    if len(total_df.loc[total_df[&#39;compound&#39;].isin(test)])/len(total_df) &gt; test_size:
                        rand = random.sample(test, 1)[0]
                        train.append(rand)
                        test.remove(rand)
        
                test_df = total_df.loc[total_df[&#39;compound&#39;].isin(test)]
                for i in test_df.index:
                    test_df.loc[i, prop] = np.nan    
                train_df = total_df.loc[total_df[&#39;compound&#39;].isin(train)]
                
                total_df = pd.concat([train_df, test_df])
                file_name = &#39;split_&#39;+p+&#39;_test.csv&#39;
                total_df.to_csv(file_name, index=False)
                save_as = file_name.split(&#39;.csv&#39;)[0]+&#39; regressed&#39;
                sig_figs = 3
                fixed_material_point = False 
                estimate_material_point = True
                self.group_property_estimator(file_name, [p])
                
                SEs=[]
                df3 = pd.read_csv(save_as+&#39;_&#39;+p+&#39;.csv&#39;)
                df3 = df3.loc[~df3[&#39;actual&#39;].isnull()]
                for c in train:
                    temp_df=df3.loc[df3[&#39;compound&#39;]==c]
                    actual=np.average(temp_df[&#39;actual&#39;].values)
                    pred = temp_df[&#39;prediction&#39;].values[0]
                    SEs.append((pred-actual)**2)
                train_RMSE = np.sqrt(np.nanmean(SEs))
                train_RMSEs.append(train_RMSE)
        
                df3 = pd.read_csv(&#39;split_&#39;+p+&#39;_test regressed_&#39;+p+&#39;.csv&#39;)
                df3 = df3.loc[df3[&#39;actual&#39;].isnull()].loc[~df3[&#39;prediction&#39;].isnull()]
                comps = []
                for k in df3.index:
                    c = df3.loc[k, &#39;compound&#39;]
                    if c not in comps:
                        comps.append(c)
                        
                SEs = []
                for c in comps:
                    pred = df3.loc[df3[&#39;compound&#39;] == c][&#39;prediction&#39;].values[0]
                    actual = np.nanmean(df.loc[df[&#39;compound&#39;] == c][p])
                    SEs.append((pred-actual)**2)
            
                test_RMSE = np.sqrt(np.nanmean(SEs))
                test_RMSEs.append(test_RMSE)
            
            dataset1 = []
            dataset2 = []
            stats_df.loc[prop_ind, &#39;property&#39;] = p
            dataset1.append(np.array(train_RMSEs))
            dataset2.append(np.array(test_RMSEs))
            avg1 = np.nanmean(train_RMSEs)
            avg2 = np.nanmean(test_RMSEs)
            stdev1 = np.std(train_RMSEs)
            stdev2 = np.std(test_RMSEs)
            stats_df.loc[prop_ind, &#39;train avg&#39;] = avg1
            stats_df.loc[prop_ind, &#39;train stdev&#39;] = stdev1
            stats_df.loc[prop_ind, &#39;test avg&#39;] = avg2
            stats_df.loc[prop_ind, &#39;test stdev&#39;] = stdev2
            
        stats_df.to_csv(output_name, index=False)
    
        if show == True:

            colors = [&#39;lightblue&#39;,&#39;orange&#39;,&#39;red&#39;,&#39;blue&#39;,&#39;sienna&#39;,&#39;pink&#39;,&#39;gold&#39;,&#39;navy&#39;,&#39;black&#39;]
            fig, ax = plt.subplots(1, len(self.props), figsize=(len(self.props)*2, 2))

            for n, p in enumerate(self.props):
                test_val = stats_df.loc[n, &#39;test avg&#39;]
                train_val = stats_df.loc[n, &#39;train avg&#39;]
                test_err = stats_df.loc[n, &#39;test stdev&#39;]
                train_err = stats_df.loc[n, &#39;train stdev&#39;]
                ax[n].bar(0, train_val, yerr = train_err, capsize=5, color=colors[n], label=&#39;train&#39;, edgecolor=&#39;black&#39;)
                ax[n].bar(1, test_val, yerr = test_err, capsize=5, color=colors[n], label=&#39;test&#39;, edgecolor=&#39;black&#39;, alpha=0.5, hatch=&#39;//&#39;)
                ax[n].set_title(self.props[n])
                ax[n].set_xticks([0, 1], [&#39;train&#39;, &#39;test&#39;])
            fig.suptitle(&#39;Train test splitting thermodynamic properties&#39;, y=1.1)
            ax[0].set_ylabel(&#39;RMSE&#39;)
            fig.subplots_adjust(wspace=0.3)
            plt.savefig(&#39;train test split barplots.pdf&#39;, bbox_inches=&#39;tight&#39;)</code></pre>
</details>
<div class="desc"><p>Regress thermodynamic properties of molecular groups for use in estimation of compounds with no experimental data.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filename</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of csv with compound names and thermodynamic properties you want to regress.</dd>
<dt><strong><code>props</code></strong> :&ensp;<code>list</code> of <code>strings</code></dt>
<dd>Thermodynamic properties you want to regress group data for. Must match the property columns in the input file.</dd>
</dl></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li>AqOrg.AqOrg.Estimate</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="propfit.propfit.PropFit.dataprep"><code class="name flex">
<span>def <span class="ident">dataprep</span></span>(<span>self, average=True, order=2, output_name=None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dataprep(self, average=True, order=2, output_name = None):

    &#34;&#34;&#34;
    Prepare a dataframe that consists of molecule names, properties, and group match data.
    
    Parameters
    ----------
    average : bool, default True
        Average repeat measurements for compound properties?

    order : numeric or str, default 2
        Order of approximation for splitting molecules into groups. Accepts &#34;2&#34;, 2, &#34;1&#34;, 1, or &#39;custom&#39;. 
        If &#39;custom&#39;, you must provide a group matching csv named &#39;custom groups.csv&#39;.  

    output_name : str, default &#39;properties and groups.csv&#39;
        Name of the CSV file that will be generated. 
    &#34;&#34;&#34;
    input_df = self.input_df
    smile_df = input_df.copy()
    if output_name == None:
        output_name = &#39;properties and groups.csv&#39;
    else:
        output_name = output_name

    for c in list(input_df.columns)[1:]:
        if c not in self.props:
            input_df.drop(c, axis=1, inplace=True)
            
    if average==True:
        new_df = pd.DataFrame(columns = input_df.columns)
        for i in input_df.index:
            c = input_df.loc[i, &#39;compound&#39;]
            if c not in list(new_df.compound):
                new_df.loc[i, &#39;compound&#39;] = c
                for p in self.props:
                    temp_df = input_df.loc[input_df[&#39;compound&#39;] == c].loc[~input_df[p].isnull()]
                    if len(temp_df)&gt;0:
                        new_df.loc[i, p] = np.nanmean(temp_df[p])
        input_df = new_df

    if isinstance(self.group_df, pd.DataFrame):
        group_df = self.group_df
    elif order == 1 or order == &#39;1&#39;:
        with import_package_file(__name__, &#39;default databases/1st order groups.csv&#39;, as_file=True) as path:
            group_df = pd.read_csv(path)
    elif order == 2 or order == &#39;2&#39;:
        with import_package_file(__name__, &#39;default databases/2nd order groups.csv&#39;, as_file=True) as path:
            group_df = pd.read_csv(path)
    
    group_df.replace(np.nan, &#39;&#39;, inplace=True)
    self.group_df = group_df

    keys = list(group_df[&#39;keys&#39;])
    values = list(group_df[&#39;values&#39;])
    pattern_dict = dict(zip(keys, values))
    for key in pattern_dict:
        if str(pattern_dict[key]) == &#39;nan&#39;:
            pattern_dict[key] = &#39;&#39;

    self.pattern_dict = pattern_dict
    
    keys += [&#39;formula&#39;]
    df = pd.DataFrame(columns = [&#39;compound&#39;]+keys)
    vetted_mol = []
    ind = 0

    molecules = list(input_df[&#34;compound&#34;])
    for molecule in molecules:
        if molecule not in vetted_mol:
            self.name = molecule

            temp_smile_df = smile_df.loc[smile_df[&#39;compound&#39;]==molecule].loc[~smile_df[&#39;SMILES&#39;].isnull()].copy()
            if len(temp_smile_df)&gt;0:
                self.smiles = temp_smile_df[&#39;SMILES&#39;].values[0]
            else:
                self.pcp_compound = pcp.get_compounds(self.name, &#34;name&#34;)
                self.smiles = self.pcp_compound[0].connectivity_smiles
            
            self.get_mol_smiles_formula_formula_dict()
            temp_dict = self.match_groups()
            values = list(temp_dict.values())
            temp_df = pd.DataFrame(columns = [&#39;compound&#39;]+keys)
            temp_df.loc[0, &#39;compound&#39;] = molecule
            temp_df.loc[0, keys] = values
            df = pd.concat([df, temp_df])
            vetted_mol.append(molecule)

    failures = len(vetted_mol) - len(molecules)
    if failures &gt; 0:
        print(&#39;There were &#39;+str(failures)+&#39; molecules that did not work&#39;)
        print([m for m in molecules if m not in vetted_mol])

    ### now add props
    key_df = pd.DataFrame(columns = keys)
    for k in keys:
        key_df[k] = [np.nan]*len(input_df)
    prop_df = pd.concat([input_df, key_df], axis=1)
    prop_df[&#39;formula&#39;] = prop_df[&#39;formula&#39;].astype(str)

    prop_df = prop_df.loc[~prop_df[&#39;compound&#39;].isnull()]        
    for i in prop_df.index:
        compound = prop_df.loc[i, &#39;compound&#39;]
        values = list(df.loc[df[&#39;compound&#39;] == compound][keys].values[0])
        prop_df.loc[i, keys] = values

    prop_df.to_csv(output_name, index=False)
    print(output_name + &#39; created&#39;)</code></pre>
</details>
<div class="desc"><p>Prepare a dataframe that consists of molecule names, properties, and group match data.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>average</code></strong> :&ensp;<code>bool</code>, default <code>True</code></dt>
<dd>Average repeat measurements for compound properties?</dd>
<dt><strong><code>order</code></strong> :&ensp;<code>numeric</code> or <code>str</code>, default <code>2</code></dt>
<dd>Order of approximation for splitting molecules into groups. Accepts "2", 2, "1", 1, or 'custom'.
If 'custom', you must provide a group matching csv named 'custom groups.csv'.</dd>
<dt><strong><code>output_name</code></strong> :&ensp;<code>str</code>, default <code>'properties and groups.csv'</code></dt>
<dd>Name of the CSV file that will be generated.</dd>
</dl></div>
</dd>
<dt id="propfit.propfit.PropFit.generate"><code class="name flex">
<span>def <span class="ident">generate</span></span>(<span>self,<br>filename='properties and groups regressed',<br>order=2,<br>hyd_props=['Gh', 'Hh', 'Cph', 'V'],<br>gas_props=['Hig', 'Sig', 'Cpig'])</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate(self, filename = &#39;properties and groups regressed&#39;, order=2, hyd_props = [&#39;Gh&#39;,&#39;Hh&#39;,&#39;Cph&#39;,&#39;V&#39;], gas_props = [&#39;Hig&#39;,&#39;Sig&#39;,&#39;Cpig&#39;]):
    
    &#34;&#34;&#34;
    Generate the group thermodynamic property databases needed to put into AqOrg&#39;s Estimate() function.
    
    Parameters
    ----------
    filename : str, default &#39;properties and groups regressed&#39;
        Common start to filenames that were generated in the group_property_estimaor() function. 

    order : numeric or str, default 2
        Order of approximation for splitting molecules into groups. Accepts &#34;2&#34;, 2, &#34;1&#34;, 1, or &#39;custom&#39;. 
        If &#39;custom&#39;, you must provide a group matching csv named &#39;custom groups.csv&#39;.
        This has to match the order which was used to make the properties and groups dataframe. 
        
    hyd_props : list of strings, default [&#39;Gh&#39;,&#39;Hh&#39;,&#39;Cph&#39;,&#39;V&#39;]
        Thermodynamic properties of hydration you want to regress group data for. Must match the property columns in the input file. 

    gas_props : list of strings, default [&#39;Hig&#39;,&#39;Sig&#39;,&#39;Cpig&#39;]
        Thermodynamic properties of formation of ideal gases you want to regress group data for. Must match the property columns in the input file.

    &#34;&#34;&#34;
    save_as = filename
    hyd_cols = []
    for h in hyd_props:
        hyd_cols += [h, h+&#39;_err&#39;, h+&#39;_n&#39;]

    gas_cols = []
    for g in gas_props:
        gas_cols += [g, g+&#39;_err&#39;, g+&#39;_n&#39;]

    group_df = self.group_df

    keys = list(group_df[&#39;keys&#39;])
    values = list(group_df[&#39;values&#39;])
    pattern_dict = dict(zip(keys, values))
    for key in pattern_dict:
        if str(pattern_dict[key]) == &#39;nan&#39;:
            pattern_dict[key] = &#39;&#39;

    self.pattern_dict = pattern_dict
    
    hyd = pd.DataFrame(columns = [&#39;group&#39;]+hyd_cols+[&#39;smarts&#39;,&#39;elem&#39;])
    temp_df = pd.read_csv(save_as+&#39;_&#39;+hyd_props[0]+&#39;_group_property.csv&#39;)
    for i in temp_df.index:
        group = temp_df.loc[i, &#39;group&#39;]
        hyd.loc[i, &#39;group&#39;] = group
        hyd.loc[i, &#39;smarts&#39;] = group
        if group != &#39;material point&#39;:
            hyd.loc[i, &#39;elem&#39;] = self.pattern_dict[group]

    group_df = pd.read_csv(save_as.split(&#39; regressed&#39;)[0]+&#39;.csv&#39;)
    ind = max([list(group_df.columns).index(p) for p in self.props])+1  
    end = list(group_df.columns).index(&#39;formula&#39;)
    groups = list(group_df.columns)[ind:end]

    remove = []
    for p in hyd_props:
        prop_df = pd.read_csv(save_as+&#39;_&#39;+p+&#39;_group_property.csv&#39;)
        err_df = pd.read_csv(save_as+&#39;_&#39;+p+&#39;_group_se.csv&#39;)
        for i in prop_df.index:
            group = prop_df.loc[i, &#39;group&#39;]
            value = prop_df.loc[i, &#39;value&#39;]
            if err_df.loc[i, &#39;group&#39;] != group:
                print(&#39;err&#39;)
            if value == 0 and i not in remove:
                remove.append(i)
            if value != 0:
                err = err_df.loc[i, &#39;std err&#39;]
                cnt = 0
                if group != &#39;material point&#39;:
                    cnt = group_df.loc[group_df[group]&gt;0][p].count()                        
                hyd.loc[i, p] = value
                hyd.loc[i, p+&#39;_err&#39;] = err
                hyd.loc[i, p+&#39;_n&#39;] = cnt
    hyd.drop(remove, inplace=True)

    gas = pd.DataFrame(columns = [&#39;group&#39;]+gas_cols+[&#39;smarts&#39;,&#39;elem&#39;])
    temp_df = pd.read_csv(save_as+&#39;_&#39;+gas_props[0]+&#39;_group_property.csv&#39;)
    for i in temp_df.index:
        group = temp_df.loc[i, &#39;group&#39;]
        gas.loc[i, &#39;group&#39;] = group
        gas.loc[i, &#39;smarts&#39;] = group
        if group != &#39;material point&#39;:
            gas.loc[i, &#39;elem&#39;] = self.pattern_dict[group]

    remove = []
    for p in gas_props:
        prop_df = pd.read_csv(save_as+&#39;_&#39;+p+&#39;_group_property.csv&#39;)
        err_df = pd.read_csv(save_as+&#39;_&#39;+p+&#39;_group_se.csv&#39;)
        for i in prop_df.index:
            group = prop_df.loc[i, &#39;group&#39;]
            value = prop_df.loc[i, &#39;value&#39;]
            if err_df.loc[i, &#39;group&#39;] != group:
                print(&#39;err&#39;)
            if value == 0 and i not in remove:
                remove.append(i)
            if value != 0:
                err = err_df.loc[i, &#39;std err&#39;]
                cnt = 0
                if group != &#39;material point&#39;:
                    cnt = group_df.loc[group_df[group]&gt;0][p].count()                        
                gas.loc[i, p] = value
                gas.loc[i, p+&#39;_err&#39;] = err
                gas.loc[i, p+&#39;_n&#39;] = cnt
    gas.drop(remove, inplace=True)
    gas.insert(1, &#39;Gig&#39;, np.nan)

    for i in gas.index:
        elements = gas.loc[i, &#39;elem&#39;]
        if str(elements) not in [&#39;nan&#39;, &#39;&#39;]:
            Selem = entropy(elements)*4.184
            Sig = gas.loc[i, &#39;Sig&#39;]
            dS = Sig - Selem
            gas.loc[i, &#39;Gig&#39;] = round((gas.loc[i, &#39;Hig&#39;]*1000 - 298.15*dS)/1000, 3)

    gas_ind = max(gas.index)+1
    gas.loc[gas_ind, :] = 0
    gas.loc[gas_ind, &#39;group&#39;]=&#39;Yo&#39;
    gas.loc[gas_ind, &#39;smarts&#39;]=&#39;Yo&#39;

    hyd_ind = hyd.loc[hyd[&#39;group&#39;]==&#39;material point&#39;].index[0]
    hyd.loc[hyd_ind, &#39;group&#39;]=&#39;Yo&#39;
    hyd.loc[hyd_ind, &#39;smarts&#39;]=&#39;Yo&#39;

    gas.to_csv(&#39;gas props.csv&#39;, index=False)
    hyd.to_csv(&#39;hyd props.csv&#39;, index=False)</code></pre>
</details>
<div class="desc"><p>Generate the group thermodynamic property databases needed to put into AqOrg's Estimate() function.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filename</code></strong> :&ensp;<code>str</code>, default <code>'properties and groups regressed'</code></dt>
<dd>Common start to filenames that were generated in the group_property_estimaor() function.</dd>
<dt><strong><code>order</code></strong> :&ensp;<code>numeric</code> or <code>str</code>, default <code>2</code></dt>
<dd>Order of approximation for splitting molecules into groups. Accepts "2", 2, "1", 1, or 'custom'.
If 'custom', you must provide a group matching csv named 'custom groups.csv'.
This has to match the order which was used to make the properties and groups dataframe.</dd>
<dt><strong><code>hyd_props</code></strong> :&ensp;<code>list</code> of <code>strings</code>, default <code>['Gh','Hh','Cph','V']</code></dt>
<dd>Thermodynamic properties of hydration you want to regress group data for. Must match the property columns in the input file.</dd>
<dt><strong><code>gas_props</code></strong> :&ensp;<code>list</code> of <code>strings</code>, default <code>['Hig','Sig','Cpig']</code></dt>
<dd>Thermodynamic properties of formation of ideal gases you want to regress group data for. Must match the property columns in the input file.</dd>
</dl></div>
</dd>
<dt id="propfit.propfit.PropFit.group_property_estimator"><code class="name flex">
<span>def <span class="ident">group_property_estimator</span></span>(<span>self, filename, props=None, ignore=None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def group_property_estimator(self, filename, props=None, ignore = None):
    
    &#34;&#34;&#34;
    Regress the properties of group matches based on thermodynamic properties of molecules and molecular group matches.
    
    Parameters
    ----------
    filename : str
        Name of the file containing compounds, properties, and group matching data. 

    props : list of strings
        Thermodynamic properties you want to regress group data for. Must match the property columns in the input file. 

    ignore : list of strings
        Name of columns in the input file which are not thermodynamic properties and therefore should not be regressed. 
    &#34;&#34;&#34;
    if not isinstance(props, list):
        props=self.props

    df1 = pd.read_csv(filename)
    
    if isinstance(ignore, list):
        df1.drop(ignore, axis=1, inplace=True)

    bad_props = []
    for p in props:
        if p not in list(df1.columns):
            bad_props.append(p)
            
    props = [p for p in props if p not in bad_props]
        
    for dependent_param in props:
        df_data = df1.copy()
        
        # remove columns containing 0 groups
        df_data = df_data.loc[:, (df_data != 0).any(axis=0)]
    
        # get data subset that needs a prediction
        df_topred = df_data[np.isfinite(df_data[dependent_param]) == False]
        
        # get data subset that does not need a prediction
        df_not_topred = df_data[np.isfinite(df_data[dependent_param]) == True]
        
        # delete rows representing compounds that need a prediction when they contain a group that is not
        # represented in the training set.
        delrows = []
        for col in df_not_topred.columns.values:
            try:
                if sum(df_not_topred[col]) == 0:
                    for row in df_topred.index.values:
                        if df_topred.loc[row, col] != 0:
                            delrows.append(row)
            except:
                pass
        bad_df = df_topred.index.isin(delrows)
        df_topred = df_topred[~bad_df]
        
        # remove rows without y values
        df_data = df_data[np.isfinite(df_data[dependent_param])]
    
        X = df_data[[x for x in list(df_data.columns.values) if not x in [&#34;compound&#34;, &#34;formula&#34;, dependent_param]+props]].copy()
        y = df_data[dependent_param].copy()
        X_topred = df_topred[[x for x in list(df_topred.columns.values) if not x in [&#34;compound&#34;, &#34;formula&#34;, dependent_param]+props]].copy()

        if &#39;ig&#39; not in dependent_param:
            
            ## add material point
            X.loc[:, &#34;material point&#34;] = [1]* len(X)
            X_topred.loc[:, &#34;material point&#34;] = [1]* len(X_topred)
            
        multi_reg = sm.OLS(y[0:], X[0:]).fit() # perform the multiple regression
        prediction = multi_reg.predict(X) # make the predictions from the multi_reg
        preds = multi_reg.predict(X_topred)
        
        material_point = 0 
        material_point_err = 0
            
        group_property_dict = dict(zip(X.columns.values, [round(val, 4) for val in multi_reg.params.values]))
        group_property_se_dict = dict(zip(X.columns.values, [round(val, 4) for val in multi_reg.bse.values]))
        pred_errs = [sum([n_group*group_property_se_dict[group]**2 for n_group, group in zip(X.loc[idx], X.columns.values)])**0.5 for idx in X.index]
        topred_errs = [sum([n_group*group_property_se_dict[group]**2 for n_group, group in zip(X_topred.loc[idx], X_topred.columns.values)])**0.5 for idx in X_topred.index]
        
        comp_pred_df = pd.DataFrame({&#34;compound&#34;:list(df_data[&#34;compound&#34;]),
                                     &#34;actual&#34;:df_data[dependent_param],
                                     &#34;prediction&#34;:[round(pred+material_point, 2) for pred in prediction.values],
                                     &#34;pred errs&#34;:[round(err, 2) for err in pred_errs]})
        
        df_preds = pd.DataFrame({&#34;compound&#34;:list(df_topred[&#34;compound&#34;]),
                                    &#34;actual&#34;:df_topred[dependent_param],
                                     &#34;prediction&#34;:[round(pred+material_point, 2) for pred in preds.values],
                                     &#34;pred errs&#34;:[round(err, 2) for err in topred_errs]})
        
        df_final = pd.concat([comp_pred_df,df_preds]) #is this happening on the right axis?
        
        with pd.option_context(&#39;display.max_rows&#39;, None, &#39;display.max_columns&#39;, None):
            df_group_property = pd.DataFrame(group_property_dict.items(), columns=[&#39;group&#39;, &#39;value&#39;])
            df_group_se = pd.DataFrame(group_property_se_dict.items(), columns=[&#39;group&#39;, &#39;std err&#39;])

        save_as = filename.split(&#39;.csv&#39;)[0]+&#39; regressed&#39;

        df_final.to_csv(save_as+&#34;_&#34;+dependent_param+&#34;.csv&#34;, index=False)
        df_group_property.to_csv(save_as+&#34;_&#34;+dependent_param+&#34;_group_property.csv&#34;, index=False) #reports 0s when not able to estimate
        df_group_se.to_csv(save_as+&#34;_&#34;+dependent_param+&#34;_group_se.csv&#34;, index=False)</code></pre>
</details>
<div class="desc"><p>Regress the properties of group matches based on thermodynamic properties of molecules and molecular group matches.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filename</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the file containing compounds, properties, and group matching data.</dd>
<dt><strong><code>props</code></strong> :&ensp;<code>list</code> of <code>strings</code></dt>
<dd>Thermodynamic properties you want to regress group data for. Must match the property columns in the input file.</dd>
<dt><strong><code>ignore</code></strong> :&ensp;<code>list</code> of <code>strings</code></dt>
<dd>Name of columns in the input file which are not thermodynamic properties and therefore should not be regressed.</dd>
</dl></div>
</dd>
<dt id="propfit.propfit.PropFit.tts"><code class="name flex">
<span>def <span class="ident">tts</span></span>(<span>self,<br>repeats=100,<br>test_size=0.2,<br>filename=None,<br>output_name='stats df.csv',<br>show=True)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def tts(self, repeats = 100, test_size = 0.2, filename = None, output_name = &#39;stats df.csv&#39;, show=True):

    &#34;&#34;&#34;
    Perform a train-test split on the thermodynamic data you will regress and estimate properties from. 
    
    Parameters
    ----------
    repeats: int, default 100
        Number of semi-random iterations of train-test splitting to do. The iterations will be used to calculate statistics associated with the semi-random sampling process.     

    test_size: float, default 0.2
        Fraction of the database for each thermodynamic property that should be used as the test set.  
    
    filename : str, default properties and groups.csv
        Common start to filenames that were generated in the group_property_estimaor() function. 

    output_name : str, default &#39;stats df.csv&#39;
        Name of the CSV file that will be generated, composed of the average and standard deviation of the RMSEs of estimations associated with each iterations. 

    show : bool, default True
        Show barplot for training and test data for each property? 
    &#34;&#34;&#34;
    if filename == None:
        filename = &#39;properties and groups.csv&#39;
    
    df = pd.read_csv(filename)
    stats_df = pd.DataFrame()
    for prop_ind, p in enumerate(self.props):
        temp_props = self.props.copy()
        temp_props.remove(p)
        prop_df = df.loc[~df[p].isnull()].drop(temp_props, axis=1)
        prop_df.reset_index(inplace=True, drop=True)
        for c in prop_df.columns[2:-1]:
            if sum(prop_df[c]) == 0:
                prop_df.drop(c, axis=1, inplace=True)

        groups = list(prop_df.columns)[2:-1]
        data_len = len(prop_df)
        prop = prop_df.columns[1]
        compounds = []
        for c in list(prop_df[&#39;compound&#39;]):
            if c not in compounds:
                compounds.append(c)

        ### sorting by least represented groups to make sampling easier below
        lengths = []
        for g in groups:
            length = len(prop_df.loc[prop_df[g]&gt;0]) #how many times is the group represented
            lengths.append(length)
        length_df = pd.DataFrame()
        length_df[&#39;groups&#39;] = groups
        length_df[&#39;lengths&#39;] = lengths
        length_df.sort_values(by = &#39;lengths&#39;, inplace=True) #least common groups first
        groups = list(length_df[&#39;groups&#39;])
    
        ### choosing one rep per group
        reps = []
        for g in groups:
            mols_w_data = []
            temp_df = prop_df.loc[prop_df[g]&gt;0].loc[~prop_df[&#39;compound&#39;].isin(reps)]
            if len(temp_df)&gt;0:
                for c in temp_df.compound:
                    if c not in mols_w_data:
                        mols_w_data.append(c)
                reps.append(random.sample(mols_w_data, 1)[0])
        non_reps = [c for c in compounds if c not in reps]
        train = reps.copy()
        test = non_reps.copy()
    
        test_df = prop_df.loc[prop_df[&#39;compound&#39;].isin(test)]
        train_df = prop_df.loc[prop_df[&#39;compound&#39;].isin(train)]
    
        test_df.to_csv(p+&#39;_test.csv&#39;, index=False) 
        train_df.to_csv(p+&#39;_train.csv&#39;, index=False) 

        train_RMSEs = []
        test_RMSEs = []
        
        for r in range(0, repeats):
    
            test_df = pd.read_csv(p+&#39;_test.csv&#39;)
            train_df = pd.read_csv(p+&#39;_train.csv&#39;) ## bare min training set so all groups are represented
            total_df = pd.concat([train_df, test_df], ignore_index=True)
            
            compounds = []
            test = []
            train = []
            for j in total_df.index:
                compound = total_df.loc[j, &#39;compound&#39;]
                if compound not in compounds:
                    compounds.append(compound)
                    if compound in list(test_df[&#39;compound&#39;]) and compound not in test:
                        test.append(compound)
                    if compound in list(train_df[&#39;compound&#39;]) and compound not in train:
                        train.append(compound)
                        
            ## randomly harvesting more data for training set
            for i in range(0, len(test)):
                if len(total_df.loc[total_df[&#39;compound&#39;].isin(test)])/len(total_df) &gt; test_size:
                    rand = random.sample(test, 1)[0]
                    train.append(rand)
                    test.remove(rand)
    
            test_df = total_df.loc[total_df[&#39;compound&#39;].isin(test)]
            for i in test_df.index:
                test_df.loc[i, prop] = np.nan    
            train_df = total_df.loc[total_df[&#39;compound&#39;].isin(train)]
            
            total_df = pd.concat([train_df, test_df])
            file_name = &#39;split_&#39;+p+&#39;_test.csv&#39;
            total_df.to_csv(file_name, index=False)
            save_as = file_name.split(&#39;.csv&#39;)[0]+&#39; regressed&#39;
            sig_figs = 3
            fixed_material_point = False 
            estimate_material_point = True
            self.group_property_estimator(file_name, [p])
            
            SEs=[]
            df3 = pd.read_csv(save_as+&#39;_&#39;+p+&#39;.csv&#39;)
            df3 = df3.loc[~df3[&#39;actual&#39;].isnull()]
            for c in train:
                temp_df=df3.loc[df3[&#39;compound&#39;]==c]
                actual=np.average(temp_df[&#39;actual&#39;].values)
                pred = temp_df[&#39;prediction&#39;].values[0]
                SEs.append((pred-actual)**2)
            train_RMSE = np.sqrt(np.nanmean(SEs))
            train_RMSEs.append(train_RMSE)
    
            df3 = pd.read_csv(&#39;split_&#39;+p+&#39;_test regressed_&#39;+p+&#39;.csv&#39;)
            df3 = df3.loc[df3[&#39;actual&#39;].isnull()].loc[~df3[&#39;prediction&#39;].isnull()]
            comps = []
            for k in df3.index:
                c = df3.loc[k, &#39;compound&#39;]
                if c not in comps:
                    comps.append(c)
                    
            SEs = []
            for c in comps:
                pred = df3.loc[df3[&#39;compound&#39;] == c][&#39;prediction&#39;].values[0]
                actual = np.nanmean(df.loc[df[&#39;compound&#39;] == c][p])
                SEs.append((pred-actual)**2)
        
            test_RMSE = np.sqrt(np.nanmean(SEs))
            test_RMSEs.append(test_RMSE)
        
        dataset1 = []
        dataset2 = []
        stats_df.loc[prop_ind, &#39;property&#39;] = p
        dataset1.append(np.array(train_RMSEs))
        dataset2.append(np.array(test_RMSEs))
        avg1 = np.nanmean(train_RMSEs)
        avg2 = np.nanmean(test_RMSEs)
        stdev1 = np.std(train_RMSEs)
        stdev2 = np.std(test_RMSEs)
        stats_df.loc[prop_ind, &#39;train avg&#39;] = avg1
        stats_df.loc[prop_ind, &#39;train stdev&#39;] = stdev1
        stats_df.loc[prop_ind, &#39;test avg&#39;] = avg2
        stats_df.loc[prop_ind, &#39;test stdev&#39;] = stdev2
        
    stats_df.to_csv(output_name, index=False)

    if show == True:

        colors = [&#39;lightblue&#39;,&#39;orange&#39;,&#39;red&#39;,&#39;blue&#39;,&#39;sienna&#39;,&#39;pink&#39;,&#39;gold&#39;,&#39;navy&#39;,&#39;black&#39;]
        fig, ax = plt.subplots(1, len(self.props), figsize=(len(self.props)*2, 2))

        for n, p in enumerate(self.props):
            test_val = stats_df.loc[n, &#39;test avg&#39;]
            train_val = stats_df.loc[n, &#39;train avg&#39;]
            test_err = stats_df.loc[n, &#39;test stdev&#39;]
            train_err = stats_df.loc[n, &#39;train stdev&#39;]
            ax[n].bar(0, train_val, yerr = train_err, capsize=5, color=colors[n], label=&#39;train&#39;, edgecolor=&#39;black&#39;)
            ax[n].bar(1, test_val, yerr = test_err, capsize=5, color=colors[n], label=&#39;test&#39;, edgecolor=&#39;black&#39;, alpha=0.5, hatch=&#39;//&#39;)
            ax[n].set_title(self.props[n])
            ax[n].set_xticks([0, 1], [&#39;train&#39;, &#39;test&#39;])
        fig.suptitle(&#39;Train test splitting thermodynamic properties&#39;, y=1.1)
        ax[0].set_ylabel(&#39;RMSE&#39;)
        fig.subplots_adjust(wspace=0.3)
        plt.savefig(&#39;train test split barplots.pdf&#39;, bbox_inches=&#39;tight&#39;)</code></pre>
</details>
<div class="desc"><p>Perform a train-test split on the thermodynamic data you will regress and estimate properties from. </p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>repeats</code></strong> :&ensp;<code>int</code>, default <code>100</code></dt>
<dd>Number of semi-random iterations of train-test splitting to do. The iterations will be used to calculate statistics associated with the semi-random sampling process.</dd>
<dt><strong><code>test_size</code></strong> :&ensp;<code>float</code>, default <code>0.2</code></dt>
<dd>Fraction of the database for each thermodynamic property that should be used as the test set.</dd>
<dt><strong><code>filename</code></strong> :&ensp;<code>str</code>, default <code>properties and groups.csv</code></dt>
<dd>Common start to filenames that were generated in the group_property_estimaor() function.</dd>
<dt><strong><code>output_name</code></strong> :&ensp;<code>str</code>, default <code>'stats df.csv'</code></dt>
<dd>Name of the CSV file that will be generated, composed of the average and standard deviation of the RMSEs of estimations associated with each iterations.</dd>
<dt><strong><code>show</code></strong> :&ensp;<code>bool</code>, default <code>True</code></dt>
<dd>Show barplot for training and test data for each property?</dd>
</dl></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="propfit" href="index.html">propfit</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="propfit.propfit.PropFit" href="#propfit.propfit.PropFit">PropFit</a></code></h4>
<ul class="">
<li><code><a title="propfit.propfit.PropFit.dataprep" href="#propfit.propfit.PropFit.dataprep">dataprep</a></code></li>
<li><code><a title="propfit.propfit.PropFit.generate" href="#propfit.propfit.PropFit.generate">generate</a></code></li>
<li><code><a title="propfit.propfit.PropFit.group_property_estimator" href="#propfit.propfit.PropFit.group_property_estimator">group_property_estimator</a></code></li>
<li><code><a title="propfit.propfit.PropFit.tts" href="#propfit.propfit.PropFit.tts">tts</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.6</a>.</p>
</footer>
</body>
</html>
